{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7308b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1db4a3",
   "metadata": {},
   "source": [
    "# 1. NumPy Bridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c16f6de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Tensor: tensor([1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "# Create a PyTorch Tensor (on CPU by default)\n",
    "tensor_cpu = torch.ones(5)\n",
    "print(f\"PyTorch Tensor: {tensor_cpu}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9e80bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted NumPy Array: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Convert Tensor to NumPy array\n",
    "# NOTE: The tensor and NumPy array will share the same memory location (on CPU),\n",
    "# so changing one will change the other!\n",
    "numpy_array = tensor_cpu.numpy()\n",
    "print(f\"Converted NumPy Array: {numpy_array}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11109ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor after modification: tensor([2., 2., 2., 2., 2.])\n",
      "Numpy array after tensor modification: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "# Modify the tensor in-place and see NumPy array change\n",
    "tensor_cpu.add_(1)\n",
    "print(f\"Tensor after modification: {tensor_cpu}\")\n",
    "print(f\"Numpy array after tensor modification: {numpy_array}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38a4335f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy Array B: [10 20 30 40 50]\n"
     ]
    }
   ],
   "source": [
    "# Create a NumPy array\n",
    "numpy_array_b = np.array([10, 20, 30, 40, 50])\n",
    "print(f\"NumPy Array B: {numpy_array_b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71c10f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted PyTorch Tensor: tensor([10, 20, 30, 40, 50])\n"
     ]
    }
   ],
   "source": [
    "# Convert NumPy array to PyTorch Tensor\n",
    "tensor_from_numpy = torch.from_numpy(numpy_array_b)\n",
    "print(f\"Converted PyTorch Tensor: {tensor_from_numpy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1885405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy array after modification: [11 21 31 41 51]\n",
      "Tensor after NumPy array modification: tensor([11, 21, 31, 41, 51])\n"
     ]
    }
   ],
   "source": [
    "# Modify the NumPy array and see the tensor change\n",
    "np.add(numpy_array_b, 1, out=numpy_array_b)\n",
    "print(f\"NumPy array after modification: {numpy_array_b}\")\n",
    "print(f\"Tensor after NumPy array modification: {tensor_from_numpy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eede76af",
   "metadata": {},
   "source": [
    "# 2. Moving Tensors between CPU and GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fde8d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU (NVIDIA GeForce RTX 4060 Laptop GPU) is available. Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\") # Use GPU\n",
    "    print(f\"GPU ({torch.cuda.get_device_name(0)}) is available. Using device: {device}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\") # Use CPU\n",
    "    print(f\"GPU not available. Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d585cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor initially on device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor (defaults to CPU)\n",
    "tensor_on_cpu = torch.randn(3, 3)\n",
    "print(f\"Tensor initially on device: {tensor_on_cpu.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81639cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor moved to device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Move the tensor to the selected device (GPU if available, else CPU)\n",
    "tensor_on_device = tensor_on_cpu.to(device)\n",
    "print(f\"Tensor moved to device: {tensor_on_device.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fe9a56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of operation on cuda:\n",
      "tensor([[ 1.0934,  1.8741,  2.6665],\n",
      "        [-0.6504,  1.5807,  0.5377],\n",
      "        [ 0.6933, -0.3728,  2.7090]], device='cuda:0')\n",
      "Result tensor is on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Perform some operation on the target device\n",
    "# NOTE: All tensors involved in an operation must be on the SAME device!\n",
    "tensor_b_on_device = torch.ones(3, 3, device=device) # Create tensor B directly on target device\n",
    "result = tensor_on_device + tensor_b_on_device\n",
    "print(f\"Result of operation on {device}:\\n{result}\")\n",
    "print(f\"Result tensor is on device: {result.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e6d8543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result moved back to CPU device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Move the result back to the CPU\n",
    "# Important if you need to convert back to NumPy or use with CPU-only libraries\n",
    "result_on_cpu = result.to(\"cpu\")\n",
    "# Alternative shorthand: result_on_cpu = result.cpu()\n",
    "print(f\"Result moved back to CPU device: {result_on_cpu.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2634e6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result converted to NumPy (after moving to CPU):\n",
      "[[ 1.0933869   1.8740594   2.6664677 ]\n",
      " [-0.65035653  1.5806998   0.53770363]\n",
      " [ 0.6933439  -0.372782    2.708973  ]]\n"
     ]
    }
   ],
   "source": [
    "# Try converting the GPU tensor directly to NumPy (will cause an error!)\n",
    "# numpy_from_gpu = result.numpy() # This would raise an error if result is on GPU\n",
    "\n",
    "# Convert the CPU tensor to NumPy (works fine)\n",
    "numpy_from_cpu = result_on_cpu.numpy()\n",
    "print(f\"Result converted to NumPy (after moving to CPU):\\n{numpy_from_cpu}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
